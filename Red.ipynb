{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando aumento de datos\n",
      "Found 2999 images belonging to 2 classes.\n",
      "Found 1999 images belonging to 2 classes.\n",
      "Entrenando modelo...\n",
      "Epoch 1/60\n",
      "30/30 [==============================] - 64s 2s/step - loss: 0.7181 - accuracy: 0.5328 - val_loss: 0.6798 - val_accuracy: 0.5478\n",
      "Epoch 2/60\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.6904 - accuracy: 0.5388 - val_loss: 0.6859 - val_accuracy: 0.6138\n",
      "Epoch 3/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.6860 - accuracy: 0.5539 - val_loss: 0.6682 - val_accuracy: 0.6143\n",
      "Epoch 4/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.6751 - accuracy: 0.5682 - val_loss: 0.6827 - val_accuracy: 0.5413\n",
      "Epoch 5/60\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.6699 - accuracy: 0.6002 - val_loss: 0.6586 - val_accuracy: 0.6058\n",
      "Epoch 6/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.6667 - accuracy: 0.5892 - val_loss: 0.6464 - val_accuracy: 0.6013\n",
      "Epoch 7/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.6395 - accuracy: 0.6252 - val_loss: 0.8289 - val_accuracy: 0.5473\n",
      "Epoch 8/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.6457 - accuracy: 0.6172 - val_loss: 0.6048 - val_accuracy: 0.6653\n",
      "Epoch 9/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.6166 - accuracy: 0.6562 - val_loss: 0.5841 - val_accuracy: 0.7084\n",
      "Epoch 10/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.6071 - accuracy: 0.6629 - val_loss: 0.5762 - val_accuracy: 0.7159\n",
      "Epoch 11/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.6018 - accuracy: 0.6749 - val_loss: 0.5344 - val_accuracy: 0.7369\n",
      "Epoch 12/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.5969 - accuracy: 0.6779 - val_loss: 0.5596 - val_accuracy: 0.7189\n",
      "Epoch 13/60\n",
      "30/30 [==============================] - 60s 2s/step - loss: 0.5770 - accuracy: 0.6992 - val_loss: 0.5305 - val_accuracy: 0.7404\n",
      "Epoch 14/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5868 - accuracy: 0.6879 - val_loss: 0.5324 - val_accuracy: 0.7299\n",
      "Epoch 15/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.5615 - accuracy: 0.7116 - val_loss: 0.5187 - val_accuracy: 0.7414\n",
      "Epoch 16/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5667 - accuracy: 0.7119 - val_loss: 0.5100 - val_accuracy: 0.7524\n",
      "Epoch 17/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5614 - accuracy: 0.7139 - val_loss: 0.6241 - val_accuracy: 0.6293\n",
      "Epoch 18/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5992 - accuracy: 0.6776 - val_loss: 0.5095 - val_accuracy: 0.7489\n",
      "Epoch 19/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5573 - accuracy: 0.7106 - val_loss: 0.5063 - val_accuracy: 0.7579\n",
      "Epoch 20/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5424 - accuracy: 0.7236 - val_loss: 0.4891 - val_accuracy: 0.7729\n",
      "Epoch 21/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5322 - accuracy: 0.7312 - val_loss: 0.4773 - val_accuracy: 0.7769\n",
      "Epoch 22/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5283 - accuracy: 0.7349 - val_loss: 0.4698 - val_accuracy: 0.7709\n",
      "Epoch 23/60\n",
      "30/30 [==============================] - 59s 2s/step - loss: 0.5313 - accuracy: 0.7239 - val_loss: 0.4684 - val_accuracy: 0.7924\n",
      "Epoch 24/60\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.5171 - accuracy: 0.7456 - val_loss: 0.4821 - val_accuracy: 0.7624\n",
      "Epoch 25/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5041 - accuracy: 0.7529 - val_loss: 0.4727 - val_accuracy: 0.7704\n",
      "Epoch 26/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5168 - accuracy: 0.7412 - val_loss: 0.5417 - val_accuracy: 0.7144\n",
      "Epoch 27/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.5242 - accuracy: 0.7439 - val_loss: 0.4697 - val_accuracy: 0.7969\n",
      "Epoch 28/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.5001 - accuracy: 0.7559 - val_loss: 0.5031 - val_accuracy: 0.7484\n",
      "Epoch 29/60\n",
      "30/30 [==============================] - 59s 2s/step - loss: 0.4913 - accuracy: 0.7623 - val_loss: 0.4227 - val_accuracy: 0.7989\n",
      "Epoch 30/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4757 - accuracy: 0.7713 - val_loss: 0.4234 - val_accuracy: 0.8064\n",
      "Epoch 31/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4771 - accuracy: 0.7739 - val_loss: 0.4572 - val_accuracy: 0.7884\n",
      "Epoch 32/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4851 - accuracy: 0.7673 - val_loss: 0.4078 - val_accuracy: 0.8159\n",
      "Epoch 33/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4636 - accuracy: 0.7789 - val_loss: 0.4048 - val_accuracy: 0.8104\n",
      "Epoch 34/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4786 - accuracy: 0.7736 - val_loss: 0.4161 - val_accuracy: 0.8119\n",
      "Epoch 35/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4679 - accuracy: 0.7786 - val_loss: 0.4150 - val_accuracy: 0.7999\n",
      "Epoch 36/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4648 - accuracy: 0.7793 - val_loss: 0.4055 - val_accuracy: 0.8134\n",
      "Epoch 37/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4528 - accuracy: 0.7893 - val_loss: 0.3754 - val_accuracy: 0.8379\n",
      "Epoch 38/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4558 - accuracy: 0.7829 - val_loss: 0.4506 - val_accuracy: 0.7784\n",
      "Epoch 39/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4289 - accuracy: 0.8036 - val_loss: 0.3958 - val_accuracy: 0.8189\n",
      "Epoch 40/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4392 - accuracy: 0.7929 - val_loss: 0.3824 - val_accuracy: 0.8314\n",
      "Epoch 41/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4226 - accuracy: 0.8059 - val_loss: 0.3677 - val_accuracy: 0.8394\n",
      "Epoch 42/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.4090 - accuracy: 0.8153 - val_loss: 0.3643 - val_accuracy: 0.8359\n",
      "Epoch 43/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4108 - accuracy: 0.8139 - val_loss: 0.3748 - val_accuracy: 0.8304\n",
      "Epoch 44/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4196 - accuracy: 0.8053 - val_loss: 0.3568 - val_accuracy: 0.8394\n",
      "Epoch 45/60\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.3905 - accuracy: 0.8199 - val_loss: 0.3556 - val_accuracy: 0.8399\n",
      "Epoch 46/60\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.4071 - accuracy: 0.8173 - val_loss: 0.3496 - val_accuracy: 0.8454\n",
      "Epoch 47/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.3972 - accuracy: 0.8256 - val_loss: 0.3402 - val_accuracy: 0.8484\n",
      "Epoch 48/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.3890 - accuracy: 0.8249 - val_loss: 0.3466 - val_accuracy: 0.8439\n",
      "Epoch 49/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.3798 - accuracy: 0.8256 - val_loss: 0.3617 - val_accuracy: 0.8394\n",
      "Epoch 50/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4126 - accuracy: 0.8189 - val_loss: 0.3362 - val_accuracy: 0.8554\n",
      "Epoch 51/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.3878 - accuracy: 0.8269 - val_loss: 0.3456 - val_accuracy: 0.8519\n",
      "Epoch 52/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.3854 - accuracy: 0.8256 - val_loss: 0.3128 - val_accuracy: 0.8654\n",
      "Epoch 53/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.3801 - accuracy: 0.8309 - val_loss: 0.3410 - val_accuracy: 0.8544\n",
      "Epoch 54/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.3571 - accuracy: 0.8353 - val_loss: 0.3218 - val_accuracy: 0.8614\n",
      "Epoch 55/60\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.3641 - accuracy: 0.8393 - val_loss: 0.3320 - val_accuracy: 0.8584\n",
      "Epoch 56/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.3639 - accuracy: 0.8343 - val_loss: 0.3563 - val_accuracy: 0.8464\n",
      "Epoch 57/60\n",
      "30/30 [==============================] - 59s 2s/step - loss: 0.3410 - accuracy: 0.8523 - val_loss: 0.3186 - val_accuracy: 0.8644\n",
      "Epoch 58/60\n",
      "30/30 [==============================] - 59s 2s/step - loss: 0.3473 - accuracy: 0.8393 - val_loss: 0.3400 - val_accuracy: 0.8464\n",
      "Epoch 59/60\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.3522 - accuracy: 0.8436 - val_loss: 0.3534 - val_accuracy: 0.8494\n",
      "Epoch 60/60\n",
      "30/30 [==============================] - 56s 2s/step - loss: 0.3474 - accuracy: 0.8493 - val_loss: 0.3151 - val_accuracy: 0.8609\n",
      "Modelo entrenado!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Variables para rutas en disco\n",
    "carpeta_base = './cats_and_dogs_filtered'\n",
    "carpeta_entrenamiento = os.path.join(carpeta_base, 'train')\n",
    "carpeta_validacion = os.path.join(carpeta_base, 'validation')\n",
    "\n",
    "carp_entren_gatos = os.path.join(carpeta_entrenamiento, 'cats')  # imagenes de gatos para pruebas\n",
    "carpeta_entren_perros = os.path.join(carpeta_entrenamiento, 'dogs')  # imagenes de perros para pruebas\n",
    "carpeta_val_gatos = os.path.join(carpeta_validacion, 'cats')  # imagenes de gatos para validacion\n",
    "carpeta_val_perros = os.path.join(carpeta_validacion, 'dogs')  # imagenes de perros para validacion\n",
    "\n",
    "#Guardar el numero de datos de entrenamiento para cada cosa\n",
    "num_gatos_entren = len(os.listdir(carp_entren_gatos))\n",
    "num_perros_entren = len(os.listdir(carpeta_entren_perros))\n",
    "num_gatos_val = len(os.listdir(carpeta_val_gatos))\n",
    "num_perros_val = len(os.listdir(carpeta_val_perros))\n",
    "total_entrenamiento = num_gatos_entren + num_perros_entren\n",
    "total_val = num_gatos_val + num_perros_val\n",
    "\n",
    "TAMANO_LOTE = 100\n",
    "TAMANO_IMG = 150\n",
    "\n",
    "#Aumento de datos (escala, rotacion, blabla)\n",
    "print(\"Realizando aumento de datos\")\n",
    "image_gen_entrenamiento = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "#Generacion de datos de entrenamiento FTW\n",
    "data_gen_entrenamiento = image_gen_entrenamiento.flow_from_directory(batch_size=TAMANO_LOTE,\n",
    "                                                     directory=carpeta_entrenamiento,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(TAMANO_IMG,TAMANO_IMG),\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "#Generacion de datos de validacion\n",
    "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data_gen_validacion = image_gen_val.flow_from_directory(batch_size=TAMANO_LOTE,\n",
    "                                                 directory=carpeta_validacion,\n",
    "                                                 target_size=(TAMANO_IMG, TAMANO_IMG),\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "#Modelo!\n",
    "modelo = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "#Compilación\n",
    "modelo.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Entrenar la red. Toma un buen rato! Ve por un café ;)\n",
    "#Oye suscribete al canal!\n",
    "print(\"Entrenando modelo...\")\n",
    "epocas=60\n",
    "history = modelo.fit(\n",
    "    data_gen_entrenamiento,\n",
    "    steps_per_epoch=int(np.ceil(total_entrenamiento / float(TAMANO_LOTE))),\n",
    "    epochs=epocas,\n",
    "    validation_data=data_gen_validacion,\n",
    "    validation_steps=int(np.ceil(total_val / float(TAMANO_LOTE)))\n",
    ")\n",
    "\n",
    "print(\"Modelo entrenado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,453,634\n",
      "Trainable params: 3,453,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save('perros-gatos-cnn-ad.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflowjs_converter --input_format keras perros-gatos-cnn-ad.h5 carpeta_salida"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd6de60cc202df302348488ddc539a0b871575196ba754f9909c09dd4d1cd470"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
